{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "69667d51",
   "metadata": {},
   "source": [
    "# SNP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "96dd6cb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pysam\n",
    "import array\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ebd5ea1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_bam = \"first_chrom.bam\"\n",
    "target_reads = \"./first_chrom_target_snp.bam\"\n",
    "untarget_reads = \"./first_chrom_untarget_snp.bam\"\n",
    "output_bam = \"./first_chrom_premod_snp.bam\"\n",
    "delete_bed = \"./snp_delete.bed\"\n",
    "snp_file = \"./snps.csv\"\n",
    "n_proc = 4\n",
    "probability = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "764bd2d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Читаем файл с мутациями\n",
    "snips = pd.read_csv(snp_file)\n",
    "\n",
    "# Создаем Bed-файл с интервалами\n",
    "with pysam.AlignmentFile(input_bam, \"rb\") as samfile_input, open(delete_bed, \"a\") as bed:\n",
    "    chroms = list(set(samfile_input.references) & set(snips[\"chromosome\"]))\n",
    "    if len(chroms) == 0:\n",
    "        # Поменять на raise\n",
    "        print(\"Target chromosomes are absent in reference\\nPlease, check correctness of your csv file or names of contigs\")\n",
    "    else:\n",
    "        snips_true = snips.query(\"chromosome in @chroms\")\n",
    "        for snip_index in snips_true.index:\n",
    "            chr_name, start = snips_true.loc[snip_index, \"chromosome\"], snips_true.loc[snip_index, \"position\"]\n",
    "            stop = start + 1\n",
    "            bed.write(f\"{chr_name}\\t{start}\\t{stop}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d2995b2",
   "metadata": {},
   "source": [
    "Самтулс"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "72b0792f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def nucl_changer(read, number_list, position, nucl, quality, comp, probability=None):\n",
    "    # По умолчанию создаем гетерозиготную мутацию (вероятность равна 0.05) \n",
    "    if (type(comp) == str) and ((\"YC\", 1) in read.get_tags()):\n",
    "        return read\n",
    "    \n",
    "    if type(probability) is not np.float64:\n",
    "        probability = 0.5\n",
    "        \n",
    "    if np.random.choice([0,1], size=1, p=[1 - probability, probability]) == 1:\n",
    "        ind = number_list.index(position - 1)\n",
    "        indq, length, rc = ind, 0, read.cigartuples\n",
    "        for cigar_block in rc:\n",
    "            if cigar_block[0] in [0, 7, 8]:\n",
    "                length += cigar_block[1]\n",
    "                if indq < length:\n",
    "                    break\n",
    "            elif cigar_block[0] in [1, 4]:\n",
    "                length += cigar_block[1]\n",
    "                indq += cigar_block[1]\n",
    "#             elif cigar_block[0] == 2:\n",
    "#                 length += cigar_block[1]\n",
    "#                 indq -= cigar_block[1]\n",
    "\n",
    "        if indq < 0:\n",
    "            print(\"Warning\", read.query_name)\n",
    "        \n",
    "        # Мутируем!            \n",
    "        read.query_sequence = read.query_sequence[:indq] + nucl + read.query_sequence[(indq + 1):]\n",
    "        if read.query_qualities is not None:\n",
    "            read.query_qualities[indq] = quality\n",
    "        if type(comp) == str:  # для компаундов\n",
    "            read.set_tag(\"YC\", 1)\n",
    "            \n",
    "    return read"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "048d0f41",
   "metadata": {},
   "outputs": [],
   "source": [
    "def snp_maker(read, number_list, snips_true, probability):\n",
    "    for snip_index in snips_true.index:\n",
    "        chr_name, position, nucl, quality, comp = snips_true.loc[snip_index, \"chromosome\"], snips_true.loc[snip_index, \"position\"], snips_true.loc[snip_index, \"nucleotide\"], snips_true.loc[snip_index, \"quality\"], snips_true.loc[snip_index, \"compaund\"]\n",
    "        probability = snips_true.loc[snip_index, \"probability\"]\n",
    "        comp_counter = []\n",
    "        if (type(comp) == str):\n",
    "            if comp not in comp_counter:\n",
    "                comp_counter.append(comp)\n",
    "                probability = 0.5\n",
    "            else:\n",
    "                probability = 1.0\n",
    "        if (position - 1) in number_list:\n",
    "            snp_read = nucl_changer(read, number_list, position, nucl, quality, comp, probability)\n",
    "    return snp_read"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b2907e75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ready\n",
    "snips = pd.read_csv(snp_file)\n",
    "\n",
    "with pysam.AlignmentFile(target_reads, \"rb\") as samfile_input, pysam.AlignmentFile(output_bam, \"wb\", template=samfile_input) as samfile_output:\n",
    "    chroms = list(set(samfile_input.references) & set(snips[\"chromosome\"]))\n",
    "    if len(chroms) == 0:\n",
    "        # Поменять на raise\n",
    "        print(\"There are no chromosomes in changed file, which needs to be changed\")\n",
    "    else:\n",
    "        snips_true = snips.query(\"chromosome in @chroms\")\n",
    "        reads = samfile_input.fetch()\n",
    "        for read in reads:\n",
    "            number_list = read.get_reference_positions()\n",
    "            read_returned = snp_maker(read, number_list, snips_true, probability)\n",
    "            samfile_output.write(read_returned)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8de596d7",
   "metadata": {},
   "source": [
    "## CNV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "12c4651b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import array\n",
    "import pysam\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "be5ae2bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_bam = \"first_chrom.bam\"\n",
    "target_reads = \"first_chrom_target_cnv.bam\"\n",
    "delete_bed = \"cnv_delete.bed\"\n",
    "output_bam = \"first_chrom_premod_cnv.bam\"\n",
    "cnv_file = \"cnv_fs3.csv\"\n",
    "target_fasta = \"./GRCh38_full_analysis_set_plus_decoy_hla.fa\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "600fcd5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создаем промежуточный bed, чтобы разнести целевой и нецелевой участки \n",
    "# (догадываюсь, что у тебя это реализовано иначе, но тем не менее запишу свой вариант)\n",
    "\n",
    "cnvs = pd.read_csv(cnv_file)\n",
    "\n",
    "with pysam.AlignmentFile(input_bam, \"rb\") as samfile_input, open(delete_bed, \"w\") as bed:\n",
    "    chroms = list(set(samfile_input.references) & set(cnvs[\"chromosome\"]))\n",
    "    if len(chroms) == 0:\n",
    "        # Поменять на raise\n",
    "        print(\"Target chromosomes are absent in reference\\nPlease, check correctness of your csv file or names of contigs\")\n",
    "    else:\n",
    "        for chr_name in chroms:  # Проходимся по каждой хромосоме, которая есть и в выравнивании, и в csv\n",
    "            chrom_subset = cnvs.query(\"chromosome==@chr_name\")\n",
    "            for cnv_num in chrom_subset.index:\n",
    "                # Сделать более гибким 1200 (задать, как переменную)\n",
    "                start, stop = chrom_subset.loc[cnv_num, \"position_start\"], chrom_subset.loc[cnv_num, \"position_finish\"]\n",
    "                bed.write(f\"{chr_name}\\t{start}\\t{stop + 1}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3170d75",
   "metadata": {},
   "source": [
    "Очень важное замечание: координаты делеций/инсерций:\n",
    "- Старт -- первый нуклеотид, которого нет / который удвоен\n",
    "- Стоп -- последний нуклеотид, которого нет / который удвоен"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b015b55f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Считает покрытие в однонуклеотидной позиции\n",
    "def read_cov_one_nucl(samfile, chr_name, nucl):\n",
    "    cov_iter = samfile.pileup(chr_name, nucl, nucl + 1, truncate=True)\n",
    "    for position in cov_iter:\n",
    "        cov = position.nsegments\n",
    "    return(cov)\n",
    "\n",
    "\n",
    "# Сохраняет кусок в +/- размер рида оснований от краев делеции\n",
    "## Переписать без дублирования кода\n",
    "## Сделать вменяемо с единицами\n",
    "def read_del_tails(samfile, chr_name, start, stop, fasta_ref, read_length=250):   # Добавить длину рида в инпут на старте или вычислять из бама\n",
    "    const = read_length * 4  # В нашем случае - 1000 нуклеотидов\n",
    "    with pysam.FastaFile(target_fasta) as fasta_ref:\n",
    "        region_left = fasta_ref.fetch(\"chr19\", start - const - 1, start - 1) # Отнимаем 1, поскольку нужно не включать первый нуклеотид делеции, формат 1-based\n",
    "        region_right = fasta_ref.fetch(\"chr19\", stop, stop + const) # Аналогичная логика\n",
    "    return region_left, region_right\n",
    "        \n",
    "# Клепаем сплит-риды\n",
    "def create_split_reads_lb(samfile_input, region_left, region_right, counter, chr_name, start, stop, read_length=250):  \n",
    "    mapq_probs = [1/80 for i in range(20,60)] + [0.5] # Эмпирическое наблюдение разброса качества рида\n",
    "    # Рандомно выбираем длину софтклипов (10-200 с каждого края)\n",
    "    min_soft = int(read_length / 25)\n",
    "    max_soft = int(read_length * 4 / 5)\n",
    "    right_num = np.random.choice(range(min_soft, max_soft), size=1)[0]\n",
    "    left_num = 250 - right_num\n",
    "    \n",
    "    # Создаем сплит-рид и добавляем его свойства\n",
    "    new_split_read = pysam.AlignedSegment(header=samfile_input.header) # Надо сделать нормальный хедер\n",
    "    new_split_read.query_name = f\"SRRread_split_l_{counter}\"  #? Это норм?\n",
    "    new_split_read.query_sequence=f\"{region_left[-left_num:]}{region_right[:right_num]}\"\n",
    "    new_split_read.reference_name = chr_name\n",
    "    if chr_name[3:] == \"X\":\n",
    "        new_split_read.reference_id = 22\n",
    "    elif chr_name[3:] == \"Y\":\n",
    "        new_split_read.reference_id = 23\n",
    "    elif type(chr_name[3:]) == int:\n",
    "        new_split_read.reference_id = int(chr_name[3:]) - 1\n",
    "    new_split_read.flag = np.random.choice([163, 99, 147, 83], size=1)[0]  #?  Допинфа от Полины и Кати\n",
    "    new_split_read.mapping_quality = np.random.choice(a=range(20,61), size=1, p=mapq_probs)[0]\n",
    "    new_split_read.reference_start = start - 1 - left_num # Потому что BAM 0-based\n",
    "    new_split_read.next_reference_id = new_split_read.reference_id\n",
    "    new_split_read.cigartuples = [(0, left_num), (4, right_num)]\n",
    "    #new_split_read.cigartuples = [(0, 250)]\n",
    "    new_split_read.query_qualities = array.array('B', np.random.choice(range(18,36), size=read_length).tolist())\n",
    "    new_split_read.tags = [(\"NM\", 1),\n",
    "          (\"RG\", \"L1\")]  #?   Допинфа от Полины и Кати\n",
    "    \n",
    "    # Создаем парный ему рид\n",
    "    \n",
    "    pair_new_split_read = pysam.AlignedSegment(header=samfile_input.header) # Надо сделать нормальный хедер\n",
    "    pair_new_split_read.query_name = f\"SRRread_split_l_{counter}\"  #? Это норм?\n",
    "    pair_new_split_read.reference_name = chr_name\n",
    "    pair_new_split_read.reference_id = new_split_read.reference_id\n",
    "\n",
    "    pair_new_split_read.mapping_quality = new_split_read.mapping_quality\n",
    "    pair_new_split_read.cigartuples = [(0, 250)]\n",
    "    pair_new_split_read.tags = [(\"NM\", 1),\n",
    "          (\"RG\", \"L1\")]  #?   Допинфа от Полины и Кати\n",
    "    pair_new_split_read.next_reference_id = new_split_read.reference_id\n",
    "\n",
    "    \n",
    "    # Если первый рид направлен направо, то:\n",
    "    if new_split_read.flag in [99, 163]:\n",
    "        next_start_coeff = np.random.choice(range(2,502), size = 1)[0] # Случайным образом отберем расстояние от второй границы делеции до старта парного рида\n",
    "        new_split_read.next_reference_start = stop + next_start_coeff\n",
    "        new_split_read.template_length = pair_new_split_read.next_reference_start - new_split_read.reference_start + 151\n",
    "        pair_new_split_read.query_sequence=f\"{region_right[next_start_coeff:next_start_coeff+250]}\"\n",
    "        if new_split_read.flag == 99:\n",
    "            pair_new_split_read.flag = 147\n",
    "        elif new_split_read.flag == 163:\n",
    "            pair_new_split_read.flag = 83\n",
    "           \n",
    "        \n",
    "    # А если налево, то:    \n",
    "    elif new_split_read.flag in [83, 147]:\n",
    "        next_start_coeff = np.random.choice(range(-750, -left_num -160), size = 1)[0] # Считаем, что риды могут перекрываться не более, чем на 90 нуклеотидов\n",
    "        new_split_read.next_reference_start = start + next_start_coeff - 1\n",
    "        new_split_read.template_length = - (new_split_read.reference_start - new_split_read.next_reference_start) - 151\n",
    "        pair_new_split_read.query_sequence = f\"{region_left[next_start_coeff:next_start_coeff+250]}\"\n",
    "        if new_split_read.flag == 147:\n",
    "            pair_new_split_read.flag = 99\n",
    "        elif new_split_read.flag == 83:\n",
    "            pair_new_split_read.flag = 163\n",
    "            \n",
    "    pair_new_split_read.reference_start = new_split_read.next_reference_start\n",
    "    pair_new_split_read.query_qualities = array.array('B', np.random.choice(range(18,36), size=read_length).tolist())\n",
    "    pair_new_split_read.next_reference_start = new_split_read.reference_start     \n",
    "    pair_new_split_read.template_length = - new_split_read.template_length \n",
    "    print(f\"first_read: {new_split_read},\\\n",
    "          second_read: {pair_new_split_read}\")\n",
    "    \n",
    "    return new_split_read, pair_new_split_read\n",
    "\n",
    "def create_split_reads_rb(samfile_input, region_left, region_right, counter, chr_name, start, stop, read_length=250):  \n",
    "    mapq_probs = [1/80 for i in range(20,60)] + [0.5] # Эмпирическое наблюдение разброса качества рида\n",
    "    min_soft = int(read_length / 25)\n",
    "    max_soft = int(read_length * 4 / 5)\n",
    "    left_num = np.random.choice(range(min_soft, max_soft), size=1)[0]\n",
    "    right_num = 250 - left_num\n",
    "    \n",
    "    # Создаем сплит-рид и добавляем его свойства\n",
    "    new_split_read = pysam.AlignedSegment(header=samfile_input.header) # Надо сделать нормальный хедер\n",
    "    new_split_read.query_name = f\"SRRread_split_r_{counter}\"  #? Это норм?\n",
    "    new_split_read.query_sequence=f\"{region_left[-left_num:]}{region_right[:right_num]}\"\n",
    "    new_split_read.reference_name = chr_name\n",
    "    if chr_name[3:] == \"X\":\n",
    "        new_split_read.reference_id = 22\n",
    "    elif chr_name[3:] == \"Y\":\n",
    "        new_split_read.reference_id = 23\n",
    "    elif type(chr_name[3:]) == int:\n",
    "        new_split_read.reference_id = int(chr_name[3:]) - 1\n",
    "    new_split_read.flag = np.random.choice([163, 99, 147, 83], size=1)[0]  #?  Допинфа от Полины и Кати\n",
    "    new_split_read.mapping_quality = np.random.choice(a=range(20,61), size=1, p=mapq_probs)[0]\n",
    "    new_split_read.reference_start = stop# - left_num # Потому что BAM 0-based\n",
    "    new_split_read.next_reference_id = new_split_read.reference_id\n",
    "    new_split_read.cigartuples = [(4, left_num), (0, right_num)]\n",
    "    #new_split_read.cigartuples = [(0, 250)]\n",
    "    new_split_read.query_qualities = array.array('B', np.random.choice(range(18,36), size=read_length).tolist())\n",
    "    new_split_read.tags = ((\"NM\", 1),\n",
    "          (\"RG\", \"L1\"))  #?   Допинфа от Полины и Кати\n",
    "    \n",
    "    # Создаем парный ему рид\n",
    "    \n",
    "    pair_new_split_read = pysam.AlignedSegment(header=samfile_input.header) # Надо сделать нормальный хедер\n",
    "    pair_new_split_read.query_name = f\"SRRread_split_r_{counter}\"  #? Это норм?\n",
    "    pair_new_split_read.reference_name = chr_name\n",
    "    pair_new_split_read.reference_id = new_split_read.reference_id\n",
    "\n",
    "    pair_new_split_read.mapping_quality = new_split_read.mapping_quality\n",
    "    pair_new_split_read.cigartuples = [(0, 250)]\n",
    "    pair_new_split_read.tags = ((\"NM\", 1),\n",
    "          (\"RG\", \"L1\"))  #?   Допинфа от Полины и Кати\n",
    "    pair_new_split_read.next_reference_id = new_split_read.reference_id\n",
    "\n",
    "    \n",
    "    # Если первый рид направлен направо, то:\n",
    "    if new_split_read.flag in [99, 163]:\n",
    "        next_start_coeff = np.random.choice(range(right_num - 90, right_num + 500), size = 1)[0] # Случайным образом отберем расстояние от второй границы делеции до старта парного рида\n",
    "        new_split_read.next_reference_start = stop + next_start_coeff\n",
    "        new_split_read.template_length = pair_new_split_read.next_reference_start - new_split_read.reference_start + 151\n",
    "        pair_new_split_read.query_sequence=f\"{region_right[next_start_coeff:next_start_coeff+250]}\"\n",
    "        if new_split_read.flag == 99:\n",
    "            pair_new_split_read.flag = 147\n",
    "        elif new_split_read.flag == 163:\n",
    "            pair_new_split_read.flag = 83\n",
    "           \n",
    "        \n",
    "    # А если налево, то:    \n",
    "    elif new_split_read.flag in [83, 147]:\n",
    "        next_start_coeff = np.random.choice(range(-750, -left_num -160), size = 1)[0] # Считаем, что риды могут перекрываться не более, чем на 90 нуклеотидов\n",
    "        new_split_read.next_reference_start = start + next_start_coeff - 1\n",
    "        new_split_read.template_length = - (new_split_read.reference_start - new_split_read.next_reference_start) - 151\n",
    "        pair_new_split_read.query_sequence = f\"{region_left[next_start_coeff:next_start_coeff+250]}\"\n",
    "        if new_split_read.flag == 147:\n",
    "            pair_new_split_read.flag = 99\n",
    "        elif new_split_read.flag == 83:\n",
    "            pair_new_split_read.flag = 163\n",
    "            \n",
    "    pair_new_split_read.reference_start = new_split_read.next_reference_start\n",
    "    pair_new_split_read.query_qualities = array.array('B', np.random.choice(range(18,36), size=read_length).tolist())\n",
    "    pair_new_split_read.next_reference_start = new_split_read.reference_start     \n",
    "    pair_new_split_read.template_length = - new_split_read.template_length \n",
    "    print(f\"first_read: {new_split_read},\\\n",
    "          second_read: {pair_new_split_read}\")\n",
    "    return new_split_read, pair_new_split_read\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "38f48c0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decreasing_coverage(samfile_input, samfile_output, chr_name, start, stop, probability):\n",
    "    reads = samfile_input.fetch(chr_name, start, stop)\n",
    "    for read in reads:\n",
    "        if (read.reference_start > start) or (read.reference_start + 250 < stop):\n",
    "            if np.random.choice([0,1], size=1, p=[1 - probability, probability]) == 0:\n",
    "                samfile_output.write(read)\n",
    "        else:\n",
    "            samfile_output.write(read)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9847202a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def increasing_coverage(samfile_input, samfile_output, chr_name, start, stop, probability):\n",
    "    reads = samfile_input.fetch(chr_name, start, stop)\n",
    "    for read in reads:\n",
    "        if (read.reference_start > start) or (read.reference_start + 250 < stop):\n",
    "            if np.random.choice([0,1], size=1, p=[1 - probability, probability]) == 1:\n",
    "                samfile_output.write(read)\n",
    "        samfile_output.write(read)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "92f585b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def duplication(samfile_input, samfile_output, chr_name, start, stop, probability):\n",
    "    increasing_coverage(samfile_input, samfile_output, chr_name, start, stop, probability)\n",
    "#     print(samfile_input.count_coverage(chr_name, start, stop, read_callback=\"nofilter\"))\n",
    "    \n",
    "    \n",
    "def deletion(samfile_input, samfile_output, chr_name, start, stop, probability, fasta_ref, lp_number=3):  # Добавить переменную гомо-гетеро для делеции и lp_number для количества \"парочек\"\n",
    "    \n",
    "    # Computing coverage, number of split reads and sequence of reference around deletion\n",
    "    coverage = (int(sum(map(lambda x: read_cov_one_nucl(samfile_input, chr_name, x), [start, stop]))/2))\n",
    "    split_num = int(coverage/3.5)\n",
    "    region_left, region_right = read_del_tails(samfile_input, chr_name, start, stop, fasta_ref) # Вычисляем контекст референса до и после делеции\n",
    "    print(split_num)\n",
    "        \n",
    "    # Creating split reads\n",
    "    counter = 0\n",
    "    for split_read in range(split_num):\n",
    "        try:\n",
    "            counter += 1\n",
    "            new_read1_lb, new_read2_lb = create_split_reads_lb(samfile_input, region_left, region_right, counter, chr_name, start, stop, probability)\n",
    "            samfile_output.write(new_read1_lb)\n",
    "            samfile_output.write(new_read2_lb)\n",
    "            new_read1_rb, new_read2_rb = create_split_reads_rb(samfile_input, region_left, region_right, counter, chr_name, start, stop, probability)\n",
    "            samfile_output.write(new_read1_rb)\n",
    "            samfile_output.write(new_read2_rb)\n",
    "        except ValueError:\n",
    "            print(\"Zdes' byl error\")\n",
    "            continue\n",
    "\n",
    "    \n",
    "    # Decreasing coverage\n",
    "    decreasing_coverage(samfile_input, samfile_output, chr_name, start, stop, probability)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b986213d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnvs = pd.read_csv(cnv_file)\n",
    "\n",
    "with pysam.AlignmentFile(target_reads, \"rb\") as samfile_input, pysam.AlignmentFile(output_bam, \"wb\", template=samfile_input) as samfile_output, pysam.FastaFile(target_fasta) as fasta_ref:\n",
    "    chroms = list(set(samfile_input.references) & set(cnvs[\"chromosome\"]))\n",
    "    true_cnvs = cnvs.query(\"chromosome in @chroms\")\n",
    "    for cnv_index in true_cnvs.index:\n",
    "        cnv_type, chr_name = true_cnvs.loc[cnv_index, \"type\"], true_cnvs.loc[cnv_index, \"chromosome\"]\n",
    "        start, stop = true_cnvs.loc[cnv_index, \"position_start\"], true_cnvs.loc[cnv_index, \"position_finish\"]\n",
    "        probability = true_cnvs.loc[cnv_index, \"probability\"]\n",
    "        if type(probability) is not np.float64:\n",
    "            probability = 0.5\n",
    "        if cnv_type == \"del\":\n",
    "            deletion(samfile_input, samfile_output, chr_name, start, stop, probability, fasta_ref)\n",
    "        elif cnv_type == \"dup\":\n",
    "            duplication(samfile_input, samfile_output, chr_name, start, stop, probability)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "488e9a3b",
   "metadata": {},
   "source": [
    "## Frameshift and another microevents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bb1c0a85",
   "metadata": {},
   "outputs": [],
   "source": [
    "import array\n",
    "import pysam\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4a31568f",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_bam = \"first_chrom.bam\"\n",
    "target_reads = \"first_chrom_target_fs.bam\"\n",
    "delete_bed = \"fs_delete.bed\"\n",
    "output_bam = \"first_chrom_premod_fs.bam\"\n",
    "fs_file = \"fs4.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5f3494d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "fs = pd.read_csv(fs_file)\n",
    "\n",
    "with pysam.AlignmentFile(input_bam, \"rb\") as samfile_input, open(delete_bed, \"w\") as bed:\n",
    "    chroms = list(set(samfile_input.references) & set(fs[\"chromosome\"]))\n",
    "    if len(chroms) == 0:\n",
    "        # Поменять на raise\n",
    "        print(\"Target chromosomes are absent in reference\\nPlease, check correctness of your csv file or names of contigs\")\n",
    "    else:\n",
    "        fs_true = fs.query(\"chromosome in @chroms\")\n",
    "        for fs_local in fs_true.index:\n",
    "            chr_name = fs_true.loc[fs_local, \"chromosome\"]\n",
    "            if pd.isna(fs_true.loc[fs_local, \"position_finish\"]):\n",
    "                start, stop = fs_true.loc[fs_local, \"position_start\"], fs_true.loc[fs_local, \"position_start\"] + 1\n",
    "            else:\n",
    "                start, stop = fs_true.loc[fs_local, \"position_start\"], int(fs_true.loc[fs_local, \"position_finish\"] + 1)\n",
    "            bed.write(f\"{chr_name}\\t{start}\\t{stop}\\n\")    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b15d70f4",
   "metadata": {},
   "source": [
    "Что-то на самтулсном"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e5fc65f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cigar_del(read, ind_list):\n",
    "    print(f\"del_ind_list: {ind_list}\\n\\\n",
    "            read_name: {read.query_name}\")\n",
    "    cigar_before = read.cigartuples        # Настраиваем строку cigar\n",
    "    cigar_after, cur_num, flag = [], 0, \"before_del\"\n",
    "    for cigartuple in cigar_before:\n",
    "        if cigartuple[0] in [1, 2, 4, 5]:   # Делеции, инсерции и клипы не учитываются в референсных позициях\n",
    "            cigar_after.append(cigartuple)\n",
    "            \n",
    "        elif cigartuple[0] == 0:\n",
    "            if flag == \"before_del\":\n",
    "                if cur_num + cigartuple[1] < ind_list[0]:\n",
    "                    cigar_after.append(cigartuple)\n",
    "                    cur_num += cigartuple[1]\n",
    "                elif cur_num + cigartuple[1] == ind_list[0]:\n",
    "                    cigar_after.append(cigartuple)\n",
    "                    cur_num += cigartuple[1]\n",
    "                    cigar_after.append((2, len(ind_list)))\n",
    "                    #cur_num += len(ind_list)\n",
    "                    flag = \"into_del\"\n",
    "                    \n",
    "                elif cur_num + cigartuple[1] > ind_list[0]:\n",
    "                    if cur_num + cigartuple[1] - 1 <= ind_list[-1]:\n",
    "                        cigar_after.append((0, ind_list[0] - cur_num))\n",
    "                        cigar_after.append((2, len(ind_list)))\n",
    "                        cur_num += (ind_list[0] - cur_num)\n",
    "                        #cur_num += len(ind_list)\n",
    "                        flag = \"after_del\"\n",
    "                    elif cur_num + cigartuple[1] - 1 > ind_list[-1]:\n",
    "                        cigar_after.append((0, ind_list[0] - cur_num))\n",
    "                        cigar_after.append((2, len(ind_list)))\n",
    "                        cigar_after.append((0, cigartuple[1] - (ind_list[0] - cur_num) - len(ind_list)))\n",
    "                        cur_num += cigartuple[1]\n",
    "                        flag = \"after_del\"\n",
    "                        \n",
    "            elif flag == \"into_del\":\n",
    "                if cur_num + cigartuple[1] - 1 <= ind_list[-1]:\n",
    "                    cur_num += cigartuple[1]\n",
    "                elif cur_num + cigartuple[1] - 1 > ind_list[-1]:\n",
    "                    cigar_after.append((0, cur_num + cigartuple[1] - 1 - ind_list[-1]))\n",
    "                    cur_num += cigartuple[1]\n",
    "                    \n",
    "            elif flag == \"after_del\":\n",
    "                cigar_after.append(cigartuple)\n",
    "\n",
    "    return cigar_after"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5efbc0a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cigar_ins(read, ins_len, start_index):\n",
    "#     if start_index is None:\n",
    "#         start_index = stop_index - 2\n",
    "    cigar_before = read.cigartuples\n",
    "    cigar_after, cur_num, flag = [], 0, \"before_ins\"\n",
    "    \n",
    "    for cigartuple in cigar_before:\n",
    "        tuplength = cigartuple[1]\n",
    "        tupletype = cigartuple[0]\n",
    "        \n",
    "        if flag == \"before_ins\":\n",
    "            if tupletype != 2:\n",
    "                if cur_num + tuplength < start_index:\n",
    "                    cigar_after.append(cigartuple)\n",
    "                    cur_num += tuplength\n",
    "                    \n",
    "                elif cur_num + tuplength == start_index:\n",
    "                    cigar_after.append(cigartuple)\n",
    "                    cur_num += tuplength\n",
    "                    if cur_num + ins_len < 250:\n",
    "                        cigar_after.append((1, ins_len))\n",
    "                        cur_num += ins_len\n",
    "                    else:\n",
    "                        new_ins_len = 250 - cur_num\n",
    "                        cigar_after.append((1, new_ins_len))\n",
    "                        cur_num += new_ins_len\n",
    "                        break\n",
    "                    flag = \"after_ins\"\n",
    "                    \n",
    "                elif cur_num + tuplength > start_index:\n",
    "                    if cur_num + tuplength + ins_len >= 250:\n",
    "                        cigar_after.append((tupletype, start_index - cur_num))\n",
    "                        cur_num += start_index - cur_num\n",
    "                        if cur_num + ins_len <= 250:\n",
    "                            cigar_after.append((1, ins_len))\n",
    "                            cur_num += ins_len\n",
    "                            cigar_after.append((tupletype, 250 - cur_num))\n",
    "                            break\n",
    "                        else:\n",
    "                            cigar_after.append((1, 250 - cur_num))\n",
    "                            break\n",
    "                        \n",
    "                    elif cur_num + tuplength + ins_len < 250:\n",
    "                        cigar_after.append((tupletype, start_index - cur_num))\n",
    "                        cigar_after.append((1, ins_len))\n",
    "                        cigar_after.append((tupletype, tuplength - (start_index - cur_num)))\n",
    "                        cur_num += tuplength\n",
    "                        cur_num += ins_len\n",
    "                        flag = \"after_ins\"\n",
    "            else:\n",
    "                cigar_after.append(cigartuple)\n",
    "                    \n",
    "        elif flag == \"after_ins\":\n",
    "            if tupletype != 2:\n",
    "                if cur_num + tuplength <= 250:\n",
    "                    cigar_after.append(cigartuple)\n",
    "                    cur_num += tuplength\n",
    "                else:\n",
    "                    cigar_after.append((tupletype, 250 - cur_num))\n",
    "                    break\n",
    "            else:\n",
    "                cigar_after.append(cigartuple)\n",
    "\n",
    "    return cigar_after"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "33d9e191",
   "metadata": {},
   "outputs": [],
   "source": [
    "def microdeletion(read, number_list, chr_name, start, stop, probability):\n",
    "    print(start, stop)\n",
    "    if np.random.choice([0,1], size=1, p=[1 - probability, probability]) == 1:\n",
    "        ind_list = []\n",
    "        for nucl in range(start, stop): # проходимся по нуклеотидам\n",
    "            if (nucl - 1) in number_list:\n",
    "                ind_list.append(number_list.index(nucl - 1)) # 0-based позиция нуклеотида в риде\n",
    "        if len(ind_list) == 0:\n",
    "            return(read)\n",
    "        \n",
    "        read.cigartuples = cigar_del(read, ind_list)\n",
    "\n",
    "        if ind_list[-1] < read.query_length - 1:  # Если последний нуклеотид из делетированных не на конце рида\n",
    "            read.query_sequence = read.query_sequence[:ind_list[0]] + read.query_sequence[(ind_list[-1]+1):]              \n",
    "        else:\n",
    "            read.query_sequence = read.query_sequence[:ind_list[0]]\n",
    "#     print(f\"del: {read.query_name}\\n\\\n",
    "#             len: {len(read.query_sequence)}\\n\\\n",
    "#             cigar: {sum([i[1] for i in read.cigartuples])}, {read.cigartuples}\\n\\\n",
    "#             start: {read.reference_start}\")\n",
    "    return read\n",
    "    \n",
    "    \n",
    "def microinsertion(read, number_list, chr_name, start, stop, seq, probability):\n",
    "    if np.random.choice([0,1], size=1, p=[1 - probability, probability]) == 1:\n",
    "        ins_len = len(seq)\n",
    "        if (start - 1 > number_list[0]) and (start < number_list[-1]):\n",
    "            start_index, stop_index = number_list.index(start ), number_list.index(start)\n",
    "            read.query_sequence = read.query_sequence[:start_index] + seq + read.query_sequence[stop_index:]\n",
    "            read.cigartuples = cigar_ins(read, ins_len, start_index)\n",
    "        elif (start - 1 > number_list[0]):\n",
    "            start_index = number_list.index(start)\n",
    "            read.query_sequence = read.query_sequence[:start_index] + seq\n",
    "            read.cigartuples = cigar_ins(read, ins_len, start_index)\n",
    "        if len(read.query_sequence) > 250:\n",
    "            read.query_sequence = read.query_sequence[:250]\n",
    "    print(f\"ins: {read.query_name}\\n\\\n",
    "        len: {len(read.query_sequence)}\\n\\\n",
    "        cigar: {sum([i[1] for i in read.cigartuples])}, {read.cigartuples}\\n\\\n",
    "        start: {read.reference_start},\\n\\\n",
    "        flag: {read.flag}\")\n",
    "    return read"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "de3455f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def microchanger(read, number_list, fs_true):  # Вместо mode в перспективе будет колонка в csv для каждого варианта\n",
    "    for fs_local in fs_true.index:\n",
    "        chr_name, fs_type, start, seq = fs_true.loc[fs_local, \"chromosome\"], fs_true.loc[fs_local, \"type\"], fs_true.loc[fs_local, \"position_start\"], fs_true.loc[fs_local, \"sequence\"]\n",
    "        probability = fs_true.loc[fs_local, \"probability\"]\n",
    "        if type(probability) is not np.float64:\n",
    "            probability = 0.5\n",
    "        if pd.isna(fs_true.loc[fs_local, \"position_finish\"]):\n",
    "            stop = fs_true.loc[fs_local, \"position_start\"] + 1\n",
    "        else:\n",
    "            stop = int(fs_true.loc[fs_local, \"position_finish\"] + 1)\n",
    "            \n",
    "        if (start in number_list) or ((stop - 1) in number_list): # Так как размер делеций предполагается меньше размера рида, если часть делеции находится на риде, то либо начало, либо конец обязательно попадут на рид\n",
    "            if fs_type == \"del\":\n",
    "                read = microdeletion(read, number_list, chr_name, start, stop, probability)\n",
    "            elif fs_type == \"ins\":\n",
    "                read = microinsertion(read, number_list, chr_name, start, stop, seq, probability)\n",
    "    return read"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d679e275",
   "metadata": {},
   "outputs": [],
   "source": [
    "fs = pd.read_csv(fs_file)\n",
    "\n",
    "with pysam.AlignmentFile(target_reads, \"rb\") as samfile_input, pysam.AlignmentFile(output_bam, \"wb\", template=samfile_input) as samfile_output:\n",
    "    chroms = list(set(samfile_input.references) & set(fs[\"chromosome\"]))\n",
    "    fs_true = fs.query(\"chromosome in @chroms\")\n",
    "    reads = samfile_input.fetch()\n",
    "    for read in reads:\n",
    "        number_list = read.get_reference_positions()\n",
    "        read_returned = microchanger(read, number_list, fs_true)\n",
    "        samfile_output.write(read_returned)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
